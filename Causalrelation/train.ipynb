{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d897b665",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70572d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import HypergraphConv\n",
    "from transformers import BertModel\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "import stanza\n",
    "\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,pos,lemma,depparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca45d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import HypergraphConv\n",
    "from transformers import BertModel\n",
    "\n",
    "class HGATLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(HGATLayer, self).__init__()\n",
    "        self.hgat = HypergraphConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, hyperedge_index):\n",
    "        return self.hgat(x, hyperedge_index)\n",
    "\n",
    "class HGATCausalClassifier(nn.Module):\n",
    "    def __init__(self, bert_model='bert-base-uncased', hidden_dim=256, out_dim=2):\n",
    "        super(HGATCausalClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model)\n",
    "        self.hgat = HGATLayer(768, hidden_dim)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, hyperedge_index):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        cls_tokens = outputs.last_hidden_state.squeeze(0) # Use [CLS] token embeddings\n",
    "         # Debugging line to check shape\n",
    "        \n",
    "        hgat_out = self.hgat(cls_tokens, hyperedge_index)\n",
    "        hgat_out = hgat_out.mean(dim=0)\n",
    "        return self.classifier(hgat_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0150ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be6a80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hyperedge_index_from_tokens(tokens, doc, max_length=128, max_hyperedges=32):\n",
    "    \"\"\"\n",
    "    Builds padded hyperedge_index from stanza `doc`.\n",
    "    Returns:\n",
    "        hyperedge_index: torch.LongTensor([2, max_hyperedges * 2])\n",
    "    \"\"\"\n",
    "    source_nodes = []\n",
    "    hyperedges = []\n",
    "\n",
    "    if not doc.sentences:\n",
    "        return torch.zeros((2, max_hyperedges * 2), dtype=torch.long)\n",
    "\n",
    "    sentence = doc.sentences[0]\n",
    "\n",
    "    # Align words to BERT tokens (simplified: 1 word â†’ 1 token)\n",
    "    word_to_token_idx = []\n",
    "    token_pos = 1  # skip [CLS]\n",
    "    for word in sentence.words:\n",
    "        if token_pos >= max_length - 1:\n",
    "            break\n",
    "        word_to_token_idx.append(token_pos)\n",
    "        token_pos += 1\n",
    "\n",
    "    for word in sentence.words:\n",
    "        head = word.head\n",
    "        dep = word.id\n",
    "\n",
    "        if head == 0:\n",
    "            continue\n",
    "\n",
    "        if head - 1 < len(word_to_token_idx) and dep - 1 < len(word_to_token_idx):\n",
    "            parent_idx = word_to_token_idx[head - 1]\n",
    "            child_idx = word_to_token_idx[dep - 1]\n",
    "\n",
    "            if parent_idx < max_length and child_idx < max_length:\n",
    "                edge_id = len(hyperedges) + 1\n",
    "                source_nodes.extend([parent_idx, child_idx])\n",
    "                hyperedges.extend([edge_id, edge_id])\n",
    "\n",
    "            if len(hyperedges) >= max_hyperedges * 2:\n",
    "                break\n",
    "\n",
    "    # Padding\n",
    "    current_len = len(hyperedges)\n",
    "    if current_len < max_hyperedges * 2:\n",
    "        pad_len = max_hyperedges * 2 - current_len\n",
    "        source_nodes += [0] * pad_len\n",
    "        hyperedges += [0] * pad_len\n",
    "    elif current_len > max_hyperedges * 2:\n",
    "        source_nodes = source_nodes[:max_hyperedges * 2]\n",
    "        hyperedges = hyperedges[:max_hyperedges * 2]\n",
    "\n",
    "    return torch.tensor([source_nodes, hyperedges], dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b26dafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalDataset(Dataset):\n",
    "    def __init__(self, csv_path, tokenizer):\n",
    "        import pandas as pd\n",
    "\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        self.labels = df[\"label\"].tolist()\n",
    "        self.sentences = df[\"input_text\"].tolist()\n",
    "\n",
    "        self.encodings = tokenizer(self.sentences, truncation=True, padding='max_length', max_length=128, return_tensors=\"pt\")\n",
    "        \n",
    "        \n",
    "        self.hyperedge_indices = []\n",
    "        for i, text in enumerate(self.sentences):\n",
    "            tokens = tokenizer.convert_ids_to_tokens(self.encodings[\"input_ids\"][i])\n",
    "            doc = nlp(text)\n",
    "            hyperedge_index = build_hyperedge_index_from_tokens(tokens, doc)\n",
    "            self.hyperedge_indices.append(hyperedge_index)\n",
    "\n",
    "\n",
    "        # Create dummy or real hyperedge indices for now (update with actual graph logic)\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(self.encodings[\"input_ids\"][idx], dtype=torch.long),\n",
    "            \"attention_mask\": torch.tensor(self.encodings[\"attention_mask\"][idx], dtype=torch.long),\n",
    "            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n",
    "            \"hyperedge_index\": self.hyperedge_indices[idx],\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f8cead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    input_ids = [item['input_ids'] for item in batch]\n",
    "    attention_mask = [item['attention_mask'] for item in batch]\n",
    "    labels = [item['label'] for item in batch]\n",
    "    hyperedge_indices = [item['hyperedge_index'] for item in batch]\n",
    "\n",
    "    input_ids = torch.nn.utils.rnn.pad_sequence(input_ids, batch_first=True, padding_value=0)\n",
    "    attention_mask = torch.nn.utils.rnn.pad_sequence(attention_mask, batch_first=True, padding_value=0)\n",
    "    labels = torch.stack(labels)\n",
    "\n",
    "    # Combine hyperedge_index tensors and shift node indices\n",
    "    hyperedge_index_combined = []\n",
    "    node_offset = 0\n",
    "    for i, edge_index in enumerate(hyperedge_indices):\n",
    "        edge_index = edge_index.clone()\n",
    "        edge_index[0, :] += node_offset  # shift node indices\n",
    "        hyperedge_index_combined.append(edge_index)\n",
    "        node_offset += batch[i]['input_ids'].size(0)\n",
    "        \n",
    "  # or len(batch[i]['input_ids'])\n",
    "\n",
    "    # Concatenate all hyperedge indices\n",
    "    hyperedge_index = torch.cat(hyperedge_index_combined, dim=1)\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"label\": labels,\n",
    "        \"hyperedge_index\": hyperedge_index,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221ab456",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "dataset = CausalDataset(\"causal_classification_dataset.csv\", tokenizer)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4178d0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size = len(dataset)\n",
    "train_size = int(0.7 * total_size)\n",
    "val_size = int(0.1 * total_size)\n",
    "test_size = total_size - train_size - val_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0b5281",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    dataset,\n",
    "    [train_size, val_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(42)  # for reproducibility\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8594911d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4)\n",
    "model = HGATCausalClassifier()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656a9af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7085204c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.__getitem__(1)['hyperedge_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499f9d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, optimizer, criterion, device, epochs=5):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in dataloader:\n",
    "            batch_size = batch['input_ids'].size(0)\n",
    "            for i in range(batch_size):\n",
    "                input_ids = batch['input_ids'][i].unsqueeze(0).to(device)\n",
    "                attention_mask = batch['attention_mask'][i].unsqueeze(0).to(device)\n",
    "                labels = batch['label'][i].unsqueeze(0).to(device)\n",
    "                \n",
    "                hyperedge_index = batch['hyperedge_index'][i].to(device) \n",
    "                 # shape: [2, N]\n",
    "                \n",
    "\n",
    "                if hyperedge_index.ndim != 2 or hyperedge_index.shape[0] != 2 :\n",
    "                    print(f\"Skipping bad hyperedge_index shape: {hyperedge_index.shape}\")\n",
    "                    continue\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(input_ids, attention_mask, hyperedge_index)\n",
    "                outputs=outputs.unsqueeze(0)\n",
    "                loss = criterion(outputs,labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6c3bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=train_model(model,train_loader,optimizer,criterion,device='cuda' if torch.cuda.is_available() else 'cpu',epochs=3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
